{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6f89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c7873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure logging\n",
    "logging.basicConfig(filename='error.log', level=logging.ERROR)\n",
    "\n",
    "chrome_path = 'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe'\n",
    "df = pd.read_excel(r'C:\\Users\\U6060174\\OneDrive - Clarivate Analytics\\Desktop\\Files\\Jupyter Notebook Work\\Excel File\\url.xlsx')\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.binary_location = chrome_path\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "retry_count = 3  # number of times to retry if an error occurs\n",
    "\n",
    "wait = WebDriverWait(driver, 30)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    url = row['{URL}']\n",
    "    name = row['{Name}']\n",
    "    assignments_name = row['{Assignments}']\n",
    "    for _ in range(retry_count):  # retry loop\n",
    "        try:\n",
    "            driver.delete_all_cookies()\n",
    "            driver.set_page_load_timeout(30)  # set a page load timeout of 30 seconds\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Click on the first element to save the first page\n",
    "            element1 = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"LeftNavLinks\"]/li[8]')))\n",
    "            element1.click()\n",
    "            \n",
    "            time.sleep(15)\n",
    "            html1 = driver.page_source\n",
    "            with open(f'C:\\\\Users\\\\U6060174\\\\OneDrive - Clarivate Analytics\\\\Desktop\\\\Files\\\\Jupyter Notebook Work\\\\Pages\\\\{name}.html', 'w', encoding='utf-8') as f:\n",
    "                f.write(html1)\n",
    "                time.sleep(5)  # add a 5 seconds delay before clicking the second element\n",
    "            \n",
    "            # Click on the second element to save the second page\n",
    "            element2 = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"link_app-data-assignments\"]')))\n",
    "            element2.click()\n",
    "            \n",
    "            time.sleep(15)\n",
    "            html2 = driver.page_source\n",
    "            with open(f'C:\\\\Users\\\\U6060174\\\\OneDrive - Clarivate Analytics\\\\Desktop\\\\Files\\\\Jupyter Notebook Work\\\\Pages\\\\{assignments_name}.html', 'w', encoding='utf-8') as f:\n",
    "                f.write(html2)\n",
    "                time.sleep(5)  # add a 5 seconds delay before moving to the next URL\n",
    "            break  # break out of the retry loop if successful\n",
    "        except (TimeoutException, WebDriverException) as e:\n",
    "            logging.error(f\"Error occurred while saving the page for {url}: {e}\")\n",
    "            print(f\"Error occurred while saving the page for {url}: {e}\")\n",
    "            time.sleep(10)  # add a 10 seconds delay before retrying\n",
    "    else:  # executed if the retry loop completes without success\n",
    "        logging.error(f\"Failed to save the page after {retry_count} retries for {url}\")\n",
    "        print(f\"Failed to save the page after {retry_count} retries for {url}\")\n",
    "    \n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3684f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the Excel file containing the URLs manual funtionality\n",
    "url_file_path = r'C:\\Users\\U6060174\\OneDrive - Clarivate Analytics\\Desktop\\Files\\Jupyter Notebook Work\\Excel File\\url_parse.xlsx'\n",
    "\n",
    "# Read the Excel file into a pandas dataframe\n",
    "df_urls = pd.read_excel(url_file_path)\n",
    "\n",
    "# Create an empty dataframe to store the parsed data\n",
    "df_data = pd.DataFrame(columns=['Name', 'Data', 'Status'])\n",
    "\n",
    "# Loop through the URLs in the dataframe and parse the HTML\n",
    "for i, row in df_urls.iterrows():\n",
    "    name = row['{Name}']\n",
    "    file_path = f'C:\\\\Users\\\\U6060174\\\\OneDrive - Clarivate Analytics\\\\Desktop\\\\Files\\\\Jupyter Notebook Work\\\\Pages\\\\{name}.html'\n",
    "    status = 'Success' # set default status as success\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            html = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        text = soup.get_text(separator='\\n')\n",
    "        text = text.replace('<div>', '<div> ')\n",
    "        text = text.replace('\\n', ' \\n')\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing the file for {name}: {e}\")\n",
    "        text = ''\n",
    "        status = 'Error' # set status as error if there's an exception\n",
    "    \n",
    "    df_data = pd.concat([df_data, pd.DataFrame({'Name': name, 'Data': text, 'Status': status}, index=[0])])\n",
    "\n",
    "# Write the parsed data to an Excel file\n",
    "output_file_path = r'C:\\Users\\U6060174\\OneDrive - Clarivate Analytics\\Desktop\\Files\\Jupyter Notebook Work\\Excel File\\scraped_data_assignments.xlsx'\n",
    "df_data.to_excel(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02bb628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b90cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777400a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81babb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
